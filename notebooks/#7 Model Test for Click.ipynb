{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/model_test_lib.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(r'..\\data\\processed\\train_v1.pkl')\n",
    "test = pd.read_pickle(r'..\\data\\processed\\test_open_pred_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[(train['is_open']) == 1].reset_index(drop=True)\n",
    "# test = test[(test['is_open']) == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_open = 'is_open'\n",
    "target_click = 'is_click'\n",
    "pid = 'id'\n",
    "campaign_id = 'campaign_id'\n",
    "user_id = 'user_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove(target_open)\n",
    "features.remove(target_click)\n",
    "features.remove(pid)\n",
    "features.remove(campaign_id)\n",
    "features.remove(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict all is_open = mode(is_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [int(train['is_click'].mode()[0])] * len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(train['is_click'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(train['is_click'], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how some basic models work without any hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['LR', 'DTC']\n",
    "model_list = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifiers(model_names, model_list, train, features, target_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tune the hyperparameter class_weight to be balanced, so that the algorithm treats them equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['LR', 'DTC']\n",
    "model_list = [\n",
    "    LogisticRegression(class_weight='balanced'),\n",
    "    DecisionTreeClassifier(class_weight='balanced')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_classifiers(model_names, model_list, train, features, target_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = ['no_of_images', 'no_of_internal_links', 'no_of_sections', 'total_links']\n",
    "derived_feature_external_link = ['no_of_external_links']\n",
    "time_features = ['day_of_week', 'time_group']\n",
    "communication_features = [col for col in features if col.startswith('communication_')]\n",
    "binned_features = [col for col in features if col.startswith('bin_')]\n",
    "sub_features = [col for col in features if col.startswith('sub -')]\n",
    "body_features = [col for col in features if col.startswith('body -')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check if newly grouped feature contains all the features\n",
    "set(features) == set(original_features + derived_feature_external_link + time_features + communication_features \n",
    "                     + binned_features + sub_features + body_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's not include the original feature and the external link features as they are already part of binned features. And create a seprate group of features that has at least 0.05 event distinguishing capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_group = time_features + communication_features + binned_features + sub_features + body_features + [target_open]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = []\n",
    "for feat in new_feature_group:\n",
    "    group = (train.groupby(feat)['is_click'].sum() / train.groupby(feat)['is_click'].count())\n",
    "    \n",
    "    if len(group) == 2:\n",
    "        present = group.get_values()[1]\n",
    "        absent = group.get_values()[0]\n",
    "        \n",
    "        if abs(present - absent) >= 0.05:\n",
    "            selected_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retest the same balanced model\n",
    "test_classifiers(model_names, model_list, train, selected_features, target_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_feature_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = select_features(train, new_feature_group, target_open, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifiers_roc_auc_score(model_names, model_list, train, selected_features, target_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['LR', 'DTC']\n",
    "model_list = [\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    DecisionTreeClassifier(class_weight='balanced', min_samples_split=0.05)\n",
    "]\n",
    "test_classifiers_roc_auc_score(model_names, model_list, train, new_feature_group, target_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(train[new_feature_group], train[target_click], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced', min_samples_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(test_y, pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the data in format lgb accepts\n",
    "# d_train = lgb.Dataset(train_X, label=train_y)\n",
    "d_train = lgb.Dataset(train[new_feature_group], label=train[target_click])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "## you can tune the parameters can try to better score\n",
    "\n",
    "params = {'task': 'train',\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'is_unbalance': True,\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.1, \n",
    "    'max_depth': 51, \n",
    "    'num_leaves': 175, \n",
    "    'feature_fraction': 0.5, \n",
    "    'max_bin': 256,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_cv = lgb.cv(params, d_train, num_boost_round=1000, nfold= 5, shuffle=True, stratified=True,\n",
    "                verbose_eval=20, early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get nround value which had lowest error\n",
    "nround_max = lgb_cv['auc-mean'].index(np.max(lgb_cv['auc-mean']))\n",
    "nround_min = lgb_cv['auc-mean'].index(np.min(lgb_cv['auc-mean']))\n",
    "print(\"MAX Rounds = \" + str(nround_max) + \" & max auc: \" + str(np.max(lgb_cv['auc-mean'])))\n",
    "print(\"MIN Rounds = \" + str(nround_min) + \" & min auc: \" + str(np.min(lgb_cv['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(params, d_train, num_boost_round=nround_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'..\\models\\model_lgbm_click_v2.pkl'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and predict\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(train[new_feature_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(train['is_click'], pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ac = -1\n",
    "best_i = -1\n",
    "for i in np.arange(0.350, 0.800, 0.001):\n",
    "    # ac = metrics.accuracy_score(test_y, np.where(preds > i, 1, 0))\n",
    "    ac = metrics.roc_auc_score(train[target_click], np.where(pred > i, 1, 0))\n",
    "    \n",
    "    if ac > best_ac:\n",
    "        print('i = ' + str(i) + ', ac = ' + str(ac))\n",
    "        best_ac = ac\n",
    "        best_i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test[new_feature_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class.sum() / len(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_click'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[pid, target_click]].to_csv(r'..\\data\\processed\\submission_lgbm_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
